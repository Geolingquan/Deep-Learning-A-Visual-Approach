This is the errata file for "Deep Learning: A Visual Approach" 
by Andrew Glassner, published by No Starch Press.

The up-to-date version of this file is maintained at
https://github.com/blueberrymusic/
           Deep-Learning-A-Visual-Approach/edit/main/Errata/errata.txt
           
This file is kept to plain text so that it can be most widely viewed.
The changes here address all errors I'm aware of, as well as omissions 
or places where the text or figures fell short of being as clear as I
intended.

Figures and Jupyter notebooks are available for free from my GitHub repo:
https://github.com/blueberrymusic/Deep-Learning-A-Visual-Approach

When a figure or notebook is corrected, I put the new figure or notebook 
in the corresponding repo, so those repos always contain the most correct 
and up to date versions.

Entries are attributed to the person who first reported the issue, or
everyone involved if it took a couple of tries to make a clear and
concise change.

TEXT AND FIGURES ...............................................................

Page 20, Figure 2-5
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   The curve is now properly normalized. 
   Changed y-axis label to probability density

Page 20
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   Replace the sentence just before Figure 2-5, beginning "This graph shows 
   us..." with:
   This graph lets us find the probability of getting back a
   value within any given range, by adding up the area under the curve
   in that range. Suppose we want to find the probability of finding a 
   car with, say, 0.45 units of oil. We don't just look up the value of
   the curve at 0.45. Instead, we imagine a little region around 0.45, 
   such as from 0.44 to 0.46, and we add up the area under the curve 
   in that region. This gives us the probability of getting back a value 
   between 0.44 and 0.46. This means that the curve can take on values 
   much greater than 1, as long as the curve is always positive, and the
   total area beneath the entire curve adds up to 1.
   
Page 33, Final paragraph, Last full sentence
  Craig Reynolds, 26 August 2021
    Replace "500 centimeters" with "500 millimeters"
    
Page 97, first paragraph
  Matthew Dority, 17 September 2021
    At the end of the paragraph, replace "P(B|A)" with "P(A|B)"
    
Page 145, First paragraph, two changes
  Jarno Mielikainen, 31 August 2021
  1. Replace "the cross entropy has its minimum value of 0)." with
  "the cross entropy has its minimum additional value of 0)." 
  2. Replace "Identical distributions have a cross entropy of 0," with
  "Identical distributions share the minimum cross entropy,"
    
Page 259, last full paragraph
  Craig Reynolds, 30 August 2021
    Replace "This is illustrated in Figure 10-47." with a new paragraph
    and revised sentence:
      Let's generalize our focus from pictures of just huskies, to
    pictures of all kinds of dogs. Suppose we'd like to write a classifier
    that can take in any photo of a dog, and tell us that dog's breed 
    (or return a catch-all category of "other"). So we'll start by giving
    PCA lots of pictures of dogs of all kinds of breeds, and have it
    produce a set of eigendogs. Now we can give PCA any new picture of
    a dog, and it will tell us the weights on the eigendogs needed to
    reproduce that image. It's those weights that we'll use as inputs
    to our classifier, rather than the pixels in the image.
       This is illustrated in Figure 10-47, where we've just shown our
    huskies, but in practice we'd use pictures of all kinds of dogs.

Page 328, Paragraph 3, Last sentence
  Andrew, 16 August 2021
    Replace "If a layer is made up" with "If a network is made up"
    
Page 466, First paragraph
 Hank Shen, 9 September 2021 
   After the second sentence, insert:
     Note that the labels T, Q, D, and R in the third column from the
     left are not definitions of those filters, which are at the top of
     the figure. Rather, these are summaries of where each of those
     filters match the four two by two blocks in the four by four
     filter to their left. 

Page 468, Figure 16-45 
 John Funge, 30 July 2021
   The bottom-most row in the leftmost image (T-map) has been removed.

NOTEBOOKS ......................................................................

Chapter-02-Statistics.ipynb
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   Figure 2-5 is now normalized
   Figure 2-5 y-axis now labeled as probability density

--------------------------- END OF ERRATA --------------------------- 
