This is the errata file for "Deep Learning: A Visual Approach" 
by Andrew Glassner, published by No Starch Press.

The up-to-date version of this file is maintained at
https://github.com/blueberrymusic/
           Deep-Learning-A-Visual-Approach/edit/main/Errata/errata.txt
           
This file is kept to plain text so that it can be most widely viewed.
The changes here address all errors I'm aware of, as well as omissions 
or places where the text or figures fell short of being as clear as I
intended.

Figures and Jupyter notebooks are available for free from my GitHub repo:
https://github.com/blueberrymusic/Deep-Learning-A-Visual-Approach

When a figure or notebook is corrected, I put the new figure or notebook 
in the corresponding repo, so those repos always contain the most correct 
and up to date versions. I won't normally update the thumbnails when I
correct an image, unless the new version is unrecognizable from the old.

Entries are attributed to the person who first reported the issue, or
everyone involved if it took a couple of tries to make a clear and
concise change.

BOOK TEXT AND FIGURES ..........................................................

Page 20, Figure 2-5
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   The curve is now properly normalized. 
   Changed y-axis label to probability density

Page 20
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   Replace the sentence just before Figure 2-5, beginning "This graph shows 
   us..." with:
   This graph lets us find the probability of getting back a
   value within any given range, by adding up the area under the curve
   in that range. Suppose we want to find the probability of finding a 
   car with, say, 0.45 units of oil. We don't just look up the value of
   the curve at 0.45. Instead, we imagine a little region around 0.45, 
   such as from 0.44 to 0.46, and we add up the area under the curve 
   in that region. This gives us the probability of getting back a value 
   between 0.44 and 0.46. This means that the curve can take on values 
   much greater than 1, as long as the curve is always positive, and the
   total area beneath the entire curve adds up to 1.
   
Page 33, Final paragraph, Last full sentence
  Craig Reynolds, 26 August 2021
    Replace "500 centimeters" with "500 millimeters"
    
Page 97, first paragraph
  Matthew Dority, 17 September 2021
    At the end of the paragraph, replace "P(B|A)" with "P(A|B)"
    
Page 145, First paragraph, two changes
  Jarno Mielikainen, 31 August 2021
  1. Replace "the cross entropy has its minimum value of 0)." with
  "the cross entropy has its minimum additional value of 0)." 
  2. Replace "Identical distributions have a cross entropy of 0," with
  "Identical distributions share the minimum cross entropy,"
    
Page 259, last full paragraph
  Craig Reynolds, 30 August 2021
    Replace "This is illustrated in Figure 10-47." with a new paragraph
    and revised sentence:
      Let's generalize our focus from pictures of just huskies, to
    pictures of all kinds of dogs. Suppose we'd like to write a classifier
    that can take in any photo of a dog, and tell us that dog's breed 
    (or return a catch-all category of "other"). So we'll start by giving
    PCA lots of pictures of dogs of all kinds of breeds, and have it
    produce a set of eigendogs. Now we can give PCA any new picture of
    a dog, and it will tell us the weights on the eigendogs needed to
    reproduce that image. It's those weights that we'll use as inputs
    to our classifier, rather than the pixels in the image.
       This is illustrated in Figure 10-47, where we've just shown our
    huskies, but in practice we'd use pictures of all kinds of dogs.

Page 328, Paragraph 3, Last sentence
  Andrew, 16 August 2021
    Replace "If a layer is made up" with "If a network is made up"
    
Page 330, First paragraph, second sentence
  Jarno Mielikainen, 17 September 2021
    Replace "E through G" with "C through G"
    
Page 363, Paragraph 3, first sentence
  Jarno Mielikainen, 17 September 2021
    Replace "multiplying Co by -4" with "multiplying that change by -4"
  
Page 416, Figure 15-36 caption
  Jarno Mielikainen, 17 September 2021
    Replace "around epoch 600" with "around epoch 425"
    
Page 437, Figure 16-10
  Dainius Vidmantas, 3 October 2021
    The 3x3 kernel in the upper right has been moved one step left.
    
Page 466, First paragraph
 Hank Shen, 9 September 2021 
   After the second sentence, insert:
     Note that the labels T, Q, L, and R in the third column from the
     left are not definitions of those filters, which are at the top of
     the figure. Rather, these are summaries of where each of those
     filters match the four two by two blocks in the four by four
     filter to their left. 

Page 468, Figure 16-45 
 John Funge, 30 July 2021
   The bottom-most row in the leftmost image (T-map) has been removed.
   
Page 663, 5th paragraph
  Jarno Mielikainen, 25 September 2021
    Replace "only 18 neurons and 54 weights" with "only 18 neurons
    and 114 weights."
    
NOTEBOOKS ......................................................................

Bonus01-Scikit-Learn-6-Automation
  Craig Reynolds, 16 October 2021
    In cell 12, poly_degree now runs from 1 to 6

Chapter-02-Statistics.ipynb
 Viktor Korsun, 18 July 2021
 Hank Shen, 2 August 2021 
   Figure 2-5 is now normalized
   Figure 2-5 y-axis now labeled as probability density
   
BONUS CHAPTERS .................................................................

Bonus Chapter 1, 2nd paragraph
  Jarno Mielikainen, 6 October 2021
    change "form almost any specific" to "from almost any specific"
    
Bonus Chapter 1, Figure B1-22, page 32
  Jarno Mielikainen, 6 October 2021
    Remove the "1" in "Parameter ranges 1"
    
Bonus Chapter 1, Listing B1-33, Page 47
  Craig Reynolds, 16 October 2021
    Remove the 0 from the dictionary for poly_degree
    
Bonus Chapter 1, Page 47
  Craig Reynolds, 16 October 2021
    Replace "7 x 4 = 28 times" with "6 x 4 = 24 times"
    
Bonus Chapter 1, Page 49, Figure B1-35
  Craig Reynolds, 16 October 2021
    The X-axis poly_degree values should run from 1 to 6
    
Bonus Chapter 1, Page 49, first paragraph
  Craig Reynolds, 16 October 2021
    After "testing score of 1.0" insert ", as did the first two
    values of alpha for degree 6."
    
Bonus Chapter 2, next to last paragraph, page 59
  Jarno Mielikainen, 6 October 2021
    Change "Listing B2-50" to "B2-48"
    
Bonus Chapter 2, 2nd paragraph, page 65
  Jarno Mielikainen, 6 October 2021
    Change "of or own" to "of our own"
    
Bonus Chapter 2, caption for Listing B2-63, page 68
  Jarno Mielikainen, 6 October 2021
    Change "created by B2-63" to "created by B2-62"
    
Bonus Chapter 3, Figure B3-6 caption, page 6
  Jarno Mielikainen, 6 October 2021
    Change "dense layers have a ReLU" to "hidden dense layers 
    have a ReLU"
    
Bonus Chapter 3, next-to-last paragraph, page 10
  Jarno Mielikainen, 6 October 2021
    Change "our two-layer model" to "our three-layer model"
    
Bonus Chapter 3, caption for Listing B3-4, page 12
  Jarno Mielikainen, 6 October 2021
    Change "Adam" to "Adam object"   
    
Bonus Chapter 3, caption for Listing B3-10, page 20
  Jarno Mielikainen, 6 October 2021
    Remove "]" at the end of the caption.

Bonus Chapter 3, caption for Listing B3-4, page 12
  Jarno Mielikainen, 6 October 2021
    Change "Adam" to "Adam object"   

Bonus Chapter 3, page 43, 4th paragraph
  Jarno Mielikainen, 6 October 2021
    Change "282832" to "28 x 28 x 32"

Bonus Chapter 3, Figure B3-33, page 48
  Jarno Mielikainen, 6 October 2021
    Accidental duplication of Figure B3-31 in the PDF. The repo
    holds the correct B3-33 (the convolution layers have striding,
    and the pooling layers are removed).

Bonus Chapter 3, Figure B3-35, page 50
  Jarno Mielikainen, 6 October 2021
    Changed "ReLU" to "No AF" on both convolution layers
    
Bonus Chapter 3, page 55, paragraphs 4-5
  Jarno Mielikainen, 6 October 2021
      The overall process of setting up and using the generator takes only
    two steps. First, we create our ImageDataGenerator with the options we want.
      Second, we train our model. As usual, we call model.fit(), but now we tell 
      it to use the data coming out the image generator. To do this, we pass 
      fit() the method flow() that is part of our image generator object, as
      shown in Listing B3-49.
    
Bonus Chapter 3, 2nd paragraph, page 59
  Jarno Mielikainen, 6 October 2021
    Replace "Our example in Chapter 19 imagined" with "For example, imagine"

Bonus Chapter 3, Figure B3-49 caption, page 62 
  Jarno Mielikainen, 6 October 2021
    Change "Figure 12-37" with "Figure 10-12"

Bonus Chapter 3, first paragraph, Page 82
  Jarno Mielikainen, 6 October 2021
    Change "at the top of the icon" to "at the right of the icon"

Bonus Chapter 3, 3rd paragraph, page 103
  Jarno Mielikainen, 6 October 2021
    Change "functional API" to "Functional API"

Bonus Chapter 3, Figure B3-96, page 104
  Jarno Mielikainen, 6 October 2021
    Change both instances of "ReLu" to "ReLU"


--------------------------- END OF ERRATA --------------------------- 
